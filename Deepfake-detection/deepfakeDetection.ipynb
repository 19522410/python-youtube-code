{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgs(path):\n",
    "    imgs = []\n",
    "    i = 0\n",
    "    for filename in os.listdir(path): \n",
    "        i += 1\n",
    "        if i == 251:\n",
    "            break\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = imread(os.path.join(path,filename))\n",
    "            resized = resize(img, (256, 256), anti_aliasing=True)\n",
    "            imgs.append(resized)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = 'deepfake_database/deepfake_database/train:test/df'\n",
    "train_real_path = 'deepfake_database/deepfake_database/train:test/real'\n",
    "deepfakes_train = readImgs(train_df_path)\n",
    "real_train = readImgs(train_real_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(deepfakes_train))\n",
    "print(len(real_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [0]*250 + [1]*250\n",
    "X_train = deepfakes_train + real_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level One: Inception Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "inception = InceptionResNetV2(include_top=False, weights=None, input_shape=(256, 256, 3))\n",
    "inception.trainable = True\n",
    "model = Sequential()\n",
    "model.add(inception)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 836s 2s/sample - loss: 1.0445 - val_loss: 0.8394\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 749s 2s/sample - loss: 0.5040 - val_loss: 0.9369\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 807s 2s/sample - loss: 0.4053 - val_loss: 1.0898\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 722s 2s/sample - loss: 0.4116 - val_loss: 0.3785\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 691s 2s/sample - loss: 0.3389 - val_loss: 0.3345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2e354350>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, validation_split = 0.2, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of the files are (df is DeepFake):\n",
      "df/elon_fake_1.png\n",
      "df/elon_fake_2.png\n",
      "df/obama_fake.png\n",
      "real/elon_real.png\n",
      "real/obama_real.png\n",
      "Predicted probability of the image being real Developer: [[0.70221025]\n",
      " [0.7025099 ]\n",
      " [0.7004069 ]\n",
      " [0.7137978 ]\n",
      " [0.72679734]] \n",
      "Predicted class : [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Deepfake detection accuracy is: 40.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The order of the files are (df is DeepFake):\")\n",
    "for name in image_names:\n",
    "        print(name)\n",
    "\n",
    "prob_real_dev = model.predict(X_test)\n",
    "actual_pred_dev = convertToActual(prob_real_dev)\n",
    "print('Predicted probability of the image being real Developer:', prob_real_dev,'\\nPredicted class :', actual_pred_dev)\n",
    "print('Deepfake detection accuracy is:', computeAccuracy(actual_pred_dev, y_test), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Two: MesoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(img_width): \n",
    "    x = Input(shape = (img_width, img_width, 3))\n",
    "    x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "    x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "        \n",
    "    x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "    x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "    y = Flatten()(x4)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(16)(y)\n",
    "    y = LeakyReLU(alpha=0.1)(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Dense(1, activation = 'sigmoid')(y)\n",
    "    return Model(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meso4 = init_model(256)\n",
    "opt = Adam(lr = 0.001)\n",
    "Meso4.compile(optimizer = opt, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 30s 76ms/step - loss: 2.0292 - val_loss: 0.7274\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 1.1109 - val_loss: 0.6889\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 20s 49ms/step - loss: 0.8715 - val_loss: 0.7026\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 23s 57ms/step - loss: 0.7349 - val_loss: 0.7127\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 24s 59ms/step - loss: 0.6808 - val_loss: 0.7215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d7a7410d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meso4.fit(X_train, y_train, batch_size = 50, validation_split = 0.2, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of the files are (df is DeepFake):\n",
      "df/elon_fake_1.png\n",
      "df/elon_fake_2.png\n",
      "df/obama_fake.png\n",
      "real/elon_real.png\n",
      "real/obama_real.png\n",
      "Predicted probability of the image being real Meso: [[0.4955473 ]\n",
      " [0.51936394]\n",
      " [0.55302715]\n",
      " [0.5075346 ]\n",
      " [0.49840945]] \n",
      "Predicted class : [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Deepfake detection accuracy is: 40.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The order of the files are (df is DeepFake):\")\n",
    "for name in image_names:\n",
    "        print(name)\n",
    "Meso4 = load_model('Meso4.h5')\n",
    "prob_real_meso = Meso4.predict(X_test)\n",
    "\n",
    "actual_pred_Meso = convertToActual(prob_real_meso)\n",
    "print('Predicted probability of the image being real Meso:', prob_real_meso,'\\nPredicted class :', actual_pred_Meso)\n",
    "print('Deepfake detection accuracy is:', computeAccuracy(actual_pred_Meso, y_test), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meso4.save('Meso4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 3: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "conv_base = Xception(include_top = False, weights = None, pooling = 'avg', input_shape = (256, 256, 3))\n",
    "\n",
    "output_layer =  Dense(activation = 'sigmoid')(conv_base.output)\n",
    "\n",
    "modified_classifier = Model(conv_base.input, output_layer)\n",
    "\n",
    "modified_classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 1304s 3s/step - loss: 0.9146 - val_loss: 0.7179\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 1665s 4s/step - loss: 0.6457 - val_loss: 0.7033\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 1435s 4s/step - loss: 0.6185 - val_loss: 0.7096\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 1564s 4s/step - loss: 0.4078 - val_loss: 0.7071\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 1549s 4s/step - loss: 0.3839 - val_loss: 0.7152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cdf3a2850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_classifier.fit(X_train, y_train, batch_size = 50, validation_split = 0.2, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_classifier.save('xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xception = load_model('xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "generator = dataGenerator.flow_from_directory(\n",
    "        'extracted_imgs',\n",
    "        shuffle=False,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=5,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "\n",
    "# Predict \n",
    "# y: Deepfake, Deepfake, Deepfake, real, real \n",
    "X_test, y_test = generator.next()\n",
    "image_names = generator.filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToActual(probs):\n",
    "    return np.round(probs)\n",
    "\n",
    "def computeAccuracy(pred, real):\n",
    "    cnt = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == real[i]:\n",
    "            cnt += 1\n",
    "    return cnt/len(pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order of the files are (df is DeepFake):\n",
      "df/elon_fake_1.png\n",
      "df/elon_fake_2.png\n",
      "df/obama_fake.png\n",
      "real/elon_real.png\n",
      "real/obama_real.png\n",
      "(5, 1)\n",
      "Predicted probability of the image being real Xception: [[0.48907715]\n",
      " [0.48908815]\n",
      " [0.48911962]\n",
      " [0.48907894]\n",
      " [0.48906732]] \n",
      "Predicted class : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Deepfake detection accuracy is: 60.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The order of the files are (df is DeepFake):\")\n",
    "for name in image_names:\n",
    "        print(name)\n",
    "\n",
    "prob_real_Xception = Xception.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "actual_pred_Xception = convertToActual(prob_real_Xception)\n",
    "print(prob_real_Xception.shape)\n",
    "print('Predicted probability of the image being real Xception:', prob_real_Xception,'\\nPredicted class :', actual_pred_Xception)\n",
    "print('Deepfake detection accuracy is:', computeAccuracy(actual_pred_Xception, y_test), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
